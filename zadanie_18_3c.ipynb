{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h18LoovCy_B8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras.layers as layers\n",
        "from keras.layers import Dense, Conv2D, Activation, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import math\n",
        "import albumentations as A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yn3-pBahombl"
      },
      "source": [
        "# Model\n",
        "\n",
        "stworzony na podstawie modelu z poprzednich części zadania."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IthVUnaozCDE"
      },
      "outputs": [],
      "source": [
        "f_mnist_model = tf.keras.Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(28, 28 ,1)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(350,activation='relu'),\n",
        "    layers.Dense(150, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "f_mnist_model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.4,\n",
        "                              patience=3, min_lr=0.00000001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3_Fr6pQlKoR"
      },
      "source": [
        "# Przygotowanie danych.\n",
        "Dane Fashion_Mnist są stworzone następująco: 60 000 przykładów treningowych oraz 10 000 przykładów testowych.\n",
        "Na zestawie treningowym (60 000) przeprowadzę technikę augmentacji. Stworzę dodatkowe dane (w sumie zbiór danych treningowych będzie 5 razy liczniejszy), które następnie podzielę na zbiór treningowy i walidacyjny w zadanym stosunku 0.9 do 0.1. Na podstawie tych danych wytrenuję model.\n",
        "Zestaw testowy pozostawiam do testowania wytrenowanego modelu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdII7j7YnC_1"
      },
      "source": [
        "## Augmentacja danych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dm0Ud7HizHWe"
      },
      "outputs": [],
      "source": [
        "def horizontal_flip (data):\n",
        "\n",
        "    horizontal_flip_images = []\n",
        "    for image in data:\n",
        "      transform = A.HorizontalFlip(p=0.5)\n",
        "      augmented_image = transform(image=image)['image']\n",
        "      horizontal_flip_images.append(augmented_image)\n",
        "    \n",
        "    images = np.array(horizontal_flip_images)\n",
        "    return images\n",
        "\n",
        "def shift_scale_rotate (data):\n",
        "\n",
        "    shift_scale_sotate_images = []\n",
        "    for image in data:\n",
        "      transform = A.ShiftScaleRotate(p=0.5)\n",
        "      augmented_image = transform(image=image)['image']\n",
        "      shift_scale_sotate_images.append(augmented_image)\n",
        "    \n",
        "    images = np.array(shift_scale_sotate_images)\n",
        "    return images\n",
        "  \n",
        "def random_rotate (data):\n",
        "\n",
        "    random_rotate_images = []\n",
        "    for image in data:\n",
        "      transform = A.RandomRotate90()\n",
        "      augmented_image = transform(image=image)['image']\n",
        "      random_rotate_images.append(augmented_image)\n",
        "    \n",
        "    images = np.array(random_rotate_images)\n",
        "    return images \n",
        "\n",
        "def transpose (data):\n",
        "\n",
        "    transpose_images = []\n",
        "    for image in data:\n",
        "      transform = A.Transpose()\n",
        "      augmented_image = transform(image=image)['image']\n",
        "      transpose_images.append(augmented_image)\n",
        "    \n",
        "    images = np.array(transpose_images)\n",
        "    return images "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXhiP2u-nV2I",
        "outputId": "a65d9ae4-d21c-465e-8ed8-593f04a98600"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "train, test = tf.keras.datasets.fashion_mnist.load_data()\n",
        "images, labels = train\n",
        "images = images/255.0\n",
        "labels = labels.astype(np.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MX-f_9T6zNGR"
      },
      "outputs": [],
      "source": [
        "images_aug1 = horizontal_flip(images)\n",
        "images_aug2 = shift_scale_rotate(images)\n",
        "images_aug3 = random_rotate(images)\n",
        "images_aug4 = transpose(images)\n",
        "\n",
        "images_transformed = np.concatenate((images_aug1,images_aug2,images_aug3,images_aug4, images), axis=0)\n",
        "labels_transformed = np.concatenate((labels, labels, labels, labels, labels), axis=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pUyLhxepED5",
        "outputId": "00b7c585-870f-4f03-effa-5b0a2444c162"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(300000, 28, 28)\n",
            "(300000,)\n"
          ]
        }
      ],
      "source": [
        "print(images_transformed.shape)\n",
        "print(labels_transformed.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6nRXpkMnxM9",
        "outputId": "26183ae0-d797-415b-dab4-bf6b167420e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1800/1800 [==============================] - 19s 6ms/step - loss: 0.5983 - accuracy: 0.7857 - val_loss: 0.3865 - val_accuracy: 0.8546 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "1800/1800 [==============================] - 11s 6ms/step - loss: 0.3601 - accuracy: 0.8708 - val_loss: 0.3146 - val_accuracy: 0.8830 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "1800/1800 [==============================] - 11s 6ms/step - loss: 0.2918 - accuracy: 0.8943 - val_loss: 0.2741 - val_accuracy: 0.9006 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "1800/1800 [==============================] - 11s 6ms/step - loss: 0.2491 - accuracy: 0.9089 - val_loss: 0.2637 - val_accuracy: 0.9032 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "1800/1800 [==============================] - 11s 6ms/step - loss: 0.2180 - accuracy: 0.9203 - val_loss: 0.2382 - val_accuracy: 0.9137 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "1800/1800 [==============================] - 11s 6ms/step - loss: 0.1932 - accuracy: 0.9291 - val_loss: 0.2481 - val_accuracy: 0.9130 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "1800/1800 [==============================] - 11s 6ms/step - loss: 0.1728 - accuracy: 0.9361 - val_loss: 0.2328 - val_accuracy: 0.9198 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "1800/1800 [==============================] - 11s 6ms/step - loss: 0.1573 - accuracy: 0.9423 - val_loss: 0.2400 - val_accuracy: 0.9210 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "1800/1800 [==============================] - 11s 6ms/step - loss: 0.1422 - accuracy: 0.9474 - val_loss: 0.2255 - val_accuracy: 0.9255 - lr: 0.0010\n",
            "Epoch 10/30\n",
            "1800/1800 [==============================] - 12s 7ms/step - loss: 0.1315 - accuracy: 0.9508 - val_loss: 0.2227 - val_accuracy: 0.9299 - lr: 0.0010\n",
            "Epoch 11/30\n",
            "1800/1800 [==============================] - 11s 6ms/step - loss: 0.1219 - accuracy: 0.9542 - val_loss: 0.2180 - val_accuracy: 0.9331 - lr: 0.0010\n",
            "Epoch 12/30\n",
            "1800/1800 [==============================] - 11s 6ms/step - loss: 0.1132 - accuracy: 0.9575 - val_loss: 0.2468 - val_accuracy: 0.9278 - lr: 0.0010\n",
            "Epoch 13/30\n",
            "1800/1800 [==============================] - 11s 6ms/step - loss: 0.1051 - accuracy: 0.9603 - val_loss: 0.2489 - val_accuracy: 0.9327 - lr: 0.0010\n",
            "Epoch 14/30\n",
            "1800/1800 [==============================] - 11s 6ms/step - loss: 0.0998 - accuracy: 0.9626 - val_loss: 0.2389 - val_accuracy: 0.9361 - lr: 0.0010\n",
            "Epoch 15/30\n",
            "1800/1800 [==============================] - 11s 6ms/step - loss: 0.0658 - accuracy: 0.9752 - val_loss: 0.2191 - val_accuracy: 0.9468 - lr: 4.0000e-04\n",
            "Epoch 16/30\n",
            "1800/1800 [==============================] - 11s 6ms/step - loss: 0.0542 - accuracy: 0.9796 - val_loss: 0.2379 - val_accuracy: 0.9462 - lr: 4.0000e-04\n",
            "Epoch 17/30\n",
            "1800/1800 [==============================] - 11s 6ms/step - loss: 0.0493 - accuracy: 0.9812 - val_loss: 0.2575 - val_accuracy: 0.9445 - lr: 4.0000e-04\n",
            "Epoch 18/30\n",
            "1800/1800 [==============================] - 11s 6ms/step - loss: 0.0361 - accuracy: 0.9865 - val_loss: 0.2418 - val_accuracy: 0.9520 - lr: 1.6000e-04\n",
            "Epoch 19/30\n",
            "1800/1800 [==============================] - 11s 6ms/step - loss: 0.0309 - accuracy: 0.9883 - val_loss: 0.2557 - val_accuracy: 0.9525 - lr: 1.6000e-04\n",
            "Epoch 20/30\n",
            "1800/1800 [==============================] - 11s 6ms/step - loss: 0.0275 - accuracy: 0.9895 - val_loss: 0.2633 - val_accuracy: 0.9530 - lr: 1.6000e-04\n",
            "Epoch 21/30\n",
            "1800/1800 [==============================] - 11s 6ms/step - loss: 0.0231 - accuracy: 0.9912 - val_loss: 0.2671 - val_accuracy: 0.9544 - lr: 6.4000e-05\n",
            "Epoch 22/30\n",
            "1800/1800 [==============================] - 11s 6ms/step - loss: 0.0212 - accuracy: 0.9921 - val_loss: 0.2735 - val_accuracy: 0.9545 - lr: 6.4000e-05\n",
            "Epoch 23/30\n",
            "1800/1800 [==============================] - 11s 6ms/step - loss: 0.0196 - accuracy: 0.9926 - val_loss: 0.2804 - val_accuracy: 0.9541 - lr: 6.4000e-05\n",
            "Epoch 24/30\n",
            "1800/1800 [==============================] - 11s 6ms/step - loss: 0.0183 - accuracy: 0.9933 - val_loss: 0.2817 - val_accuracy: 0.9552 - lr: 2.5600e-05\n",
            "Epoch 25/30\n",
            "1800/1800 [==============================] - 11s 6ms/step - loss: 0.0173 - accuracy: 0.9936 - val_loss: 0.2850 - val_accuracy: 0.9552 - lr: 2.5600e-05\n",
            "Epoch 26/30\n",
            "1800/1800 [==============================] - 11s 6ms/step - loss: 0.0167 - accuracy: 0.9938 - val_loss: 0.2882 - val_accuracy: 0.9554 - lr: 2.5600e-05\n",
            "Epoch 27/30\n",
            "1800/1800 [==============================] - 11s 6ms/step - loss: 0.0160 - accuracy: 0.9941 - val_loss: 0.2887 - val_accuracy: 0.9555 - lr: 1.0240e-05\n",
            "Epoch 28/30\n",
            "1800/1800 [==============================] - 11s 6ms/step - loss: 0.0157 - accuracy: 0.9941 - val_loss: 0.2899 - val_accuracy: 0.9557 - lr: 1.0240e-05\n",
            "Epoch 29/30\n",
            "1800/1800 [==============================] - 11s 6ms/step - loss: 0.0154 - accuracy: 0.9944 - val_loss: 0.2912 - val_accuracy: 0.9558 - lr: 1.0240e-05\n",
            "Epoch 30/30\n",
            "1800/1800 [==============================] - 11s 6ms/step - loss: 0.0154 - accuracy: 0.9942 - val_loss: 0.2913 - val_accuracy: 0.9557 - lr: 4.0960e-06\n"
          ]
        }
      ],
      "source": [
        "X_train, X_val, y_train, y_val = \\\n",
        "    train_test_split(images_transformed, labels_transformed, test_size=0.1, random_state=4321, stratify=labels_transformed)\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "train_ds = train_ds.batch(150)\n",
        "\n",
        "train_stats = f_mnist_model.fit(train_ds, epochs=30,callbacks=[reduce_lr],validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGeL_v37paXw"
      },
      "source": [
        "# Dokładność modelu\n",
        "Na podstawie danych testowych pochodzących z pierwotnego (bez augmentacji) zbioru danych Fashion_Mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMFa1alpzo9T",
        "outputId": "a761d398-4a3c-44e6-9893-145df0ab4941"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7868 - accuracy: 0.9211\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.7868013978004456, 0.9211000204086304]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train, test = tf.keras.datasets.fashion_mnist.load_data()\n",
        "images, labels = test\n",
        "images = images/255.0\n",
        "labels = labels.astype(np.int32)\n",
        "score = f_mnist_model.evaluate(images, labels)\n",
        "score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd5lMuxTsqej"
      },
      "source": [
        "# Wnioski:\n",
        "\n",
        "Uważam, że nie jest źle. Model bywał przetrenowywany, więc w celu złagodzenia tej sytuacji zastosowałam w modelu Dropout().\n",
        "\n",
        "W internecie (przynajmniej tam, gdzie ja dotarłam) rzadko kto zwraca uwagę na accuracy na danych testowych. Wystarcza, że sam wytrenowany na danych treningowych model ma wysoką dokładność i nie zwraca się uwagi na przetrenowanie modelu. W tych okolicznościach osiągnięcie przez laika (czyli mnie) accuracy ~.92 na danych testowych uważam za sukces.\n",
        "\n",
        "Zauważyłam też, że powszechnie błędnie stosuje się technikę augmentacji. Zazwyczaj ludzie zmieniali dane i jako takie zmienione trenowali. Nie dodawali wykreowanych danych do podstawowego datasetu tylko trenowali modele na przekształconych danych. Nie zwiększali liczebności danych treningowych, a to na tym, zdaje się, polega augmentacja."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
