{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras.layers as layers\n",
        "from keras.layers import Dense, Conv2D, Activation, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import math\n",
        "import albumentations as A"
      ],
      "metadata": {
        "id": "4Yt1_wuwWbmS"
      },
      "id": "4Yt1_wuwWbmS",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n",
        "\n",
        "stworzony na podstawie modelu z poprzednich części zadania."
      ],
      "metadata": {
        "id": "ZUy0ApJb7b8I"
      },
      "id": "ZUy0ApJb7b8I"
    },
    {
      "cell_type": "code",
      "source": [
        "f_mnist_model = tf.keras.Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(28, 28 ,1)),\n",
        "    MaxPooling2D(),\n",
        "    Dropout(0.3),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Dropout(0.5),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(350,activation='relu'),\n",
        "    layers.Dense(150, activation='relu'),\n",
        "    Dropout(0.25),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "f_mnist_model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                              patience=4, min_lr=0.00000001)"
      ],
      "metadata": {
        "id": "xo7cT8T9WcTG"
      },
      "id": "xo7cT8T9WcTG",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Przygotowanie danych.\n",
        "Dane Fashion_Mnist są stworzone następująco: 60 000 przykładów treningowych oraz 10 000 przykładów testowych.\n",
        "Na zestawie treningowym (60 000) przeprowadzę technikę augmentacji. Stworzę dodatkowe dane (w sumie zbiór danych treningowych będzie 2 razy liczniejszy), które następnie podzielę na zbiór treningowy i walidacyjny w zadanym stosunku 0.9 do 0.1. Na podstawie tych danych wytrenuję model.\n",
        "Zestaw testowy pozostawiam do testowania wytrenowanego modelu."
      ],
      "metadata": {
        "id": "ULPYdGQn7lBN"
      },
      "id": "ULPYdGQn7lBN"
    },
    {
      "cell_type": "code",
      "source": [
        "def augmentation (data):\n",
        "\n",
        "    augmented_images = []\n",
        "\n",
        "    for image in data:\n",
        "      transform1 = A.HorizontalFlip(p=0.5)\n",
        "      transform2 = A.RandomRotate90()\n",
        "      transform3 = A.Transpose()\n",
        "      transform4 = A.Blur(blur_limit=3)\n",
        "      transform5 = A.OpticalDistortion()\n",
        "      transform6 = A.GridDistortion()\n",
        "      augmented_image = transform1(image=image)['image']\n",
        "      augmented_image = transform2(image=image)['image']\n",
        "      augmented_image = transform3(image=image)['image']\n",
        "      augmented_image = transform4(image=image)['image']\n",
        "      augmented_image = transform5(image=image)['image']\n",
        "      augmented_image = transform6(image=image)['image']\n",
        "\n",
        "      augmented_images.append(augmented_image)\n",
        "    \n",
        "    images = np.array(augmented_images)\n",
        "    return images"
      ],
      "metadata": {
        "id": "zD7woBLHWwD3"
      },
      "id": "zD7woBLHWwD3",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = tf.keras.datasets.fashion_mnist.load_data()\n",
        "images, labels = train\n",
        "images = images/255.0\n",
        "labels = labels.astype(np.int32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZLw2Zjx3hqi",
        "outputId": "abb378c4-390c-46d3-e826-bed3bb1dbeec"
      },
      "id": "dZLw2Zjx3hqi",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images_aug = augmentation(images)\n",
        "\n",
        "images_transformed = np.concatenate((images_aug, images), axis=0)\n",
        "labels_transformed = np.concatenate((labels, labels), axis=None)"
      ],
      "metadata": {
        "id": "9AC-EfRR342I"
      },
      "id": "9AC-EfRR342I",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(images_transformed.shape)\n",
        "print(labels_transformed.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncblm27P37oh",
        "outputId": "16037e60-7a1a-49da-8051-4fbdda7a09e6"
      },
      "id": "ncblm27P37oh",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(120000, 28, 28)\n",
            "(120000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = \\\n",
        "    train_test_split(images_transformed, labels_transformed, test_size=0.1, random_state=4321, stratify=labels_transformed)\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "train_ds = train_ds.batch(128)\n",
        "\n",
        "train_stats = f_mnist_model.fit(train_ds, epochs=85,callbacks=[reduce_lr],validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2v0J9LX3-aZ",
        "outputId": "ab797a85-feba-4a4d-91bb-dae2c76d959b"
      },
      "id": "f2v0J9LX3-aZ",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/85\n",
            "844/844 [==============================] - 13s 7ms/step - loss: 0.6842 - accuracy: 0.7425 - val_loss: 0.4249 - val_accuracy: 0.8386 - lr: 0.0010\n",
            "Epoch 2/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.4539 - accuracy: 0.8307 - val_loss: 0.3453 - val_accuracy: 0.8701 - lr: 0.0010\n",
            "Epoch 3/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.3978 - accuracy: 0.8518 - val_loss: 0.3061 - val_accuracy: 0.8826 - lr: 0.0010\n",
            "Epoch 4/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.3630 - accuracy: 0.8643 - val_loss: 0.2785 - val_accuracy: 0.8952 - lr: 0.0010\n",
            "Epoch 5/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.3409 - accuracy: 0.8725 - val_loss: 0.2622 - val_accuracy: 0.9031 - lr: 0.0010\n",
            "Epoch 6/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.3238 - accuracy: 0.8788 - val_loss: 0.2490 - val_accuracy: 0.9062 - lr: 0.0010\n",
            "Epoch 7/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.3102 - accuracy: 0.8829 - val_loss: 0.2447 - val_accuracy: 0.9077 - lr: 0.0010\n",
            "Epoch 8/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.2973 - accuracy: 0.8887 - val_loss: 0.2383 - val_accuracy: 0.9103 - lr: 0.0010\n",
            "Epoch 9/85\n",
            "844/844 [==============================] - 7s 8ms/step - loss: 0.2885 - accuracy: 0.8916 - val_loss: 0.2378 - val_accuracy: 0.9122 - lr: 0.0010\n",
            "Epoch 10/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.2792 - accuracy: 0.8959 - val_loss: 0.2293 - val_accuracy: 0.9148 - lr: 0.0010\n",
            "Epoch 11/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.2713 - accuracy: 0.8987 - val_loss: 0.2184 - val_accuracy: 0.9188 - lr: 0.0010\n",
            "Epoch 12/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.2673 - accuracy: 0.8996 - val_loss: 0.2166 - val_accuracy: 0.9195 - lr: 0.0010\n",
            "Epoch 13/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.2640 - accuracy: 0.8992 - val_loss: 0.2102 - val_accuracy: 0.9192 - lr: 0.0010\n",
            "Epoch 14/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.2572 - accuracy: 0.9031 - val_loss: 0.2125 - val_accuracy: 0.9207 - lr: 0.0010\n",
            "Epoch 15/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.2549 - accuracy: 0.9042 - val_loss: 0.2045 - val_accuracy: 0.9241 - lr: 0.0010\n",
            "Epoch 16/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.2489 - accuracy: 0.9056 - val_loss: 0.2043 - val_accuracy: 0.9223 - lr: 0.0010\n",
            "Epoch 17/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.2477 - accuracy: 0.9064 - val_loss: 0.2047 - val_accuracy: 0.9233 - lr: 0.0010\n",
            "Epoch 18/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.2431 - accuracy: 0.9075 - val_loss: 0.2063 - val_accuracy: 0.9219 - lr: 0.0010\n",
            "Epoch 19/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.2416 - accuracy: 0.9085 - val_loss: 0.1953 - val_accuracy: 0.9260 - lr: 0.0010\n",
            "Epoch 20/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.2357 - accuracy: 0.9110 - val_loss: 0.2040 - val_accuracy: 0.9229 - lr: 0.0010\n",
            "Epoch 21/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.2342 - accuracy: 0.9127 - val_loss: 0.1939 - val_accuracy: 0.9265 - lr: 0.0010\n",
            "Epoch 22/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.2322 - accuracy: 0.9108 - val_loss: 0.1926 - val_accuracy: 0.9296 - lr: 0.0010\n",
            "Epoch 23/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.2295 - accuracy: 0.9126 - val_loss: 0.1916 - val_accuracy: 0.9277 - lr: 0.0010\n",
            "Epoch 24/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.2269 - accuracy: 0.9144 - val_loss: 0.1936 - val_accuracy: 0.9278 - lr: 0.0010\n",
            "Epoch 25/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.2240 - accuracy: 0.9141 - val_loss: 0.1843 - val_accuracy: 0.9327 - lr: 0.0010\n",
            "Epoch 26/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.2240 - accuracy: 0.9150 - val_loss: 0.1871 - val_accuracy: 0.9304 - lr: 0.0010\n",
            "Epoch 27/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.2213 - accuracy: 0.9157 - val_loss: 0.1833 - val_accuracy: 0.9302 - lr: 0.0010\n",
            "Epoch 28/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.2180 - accuracy: 0.9176 - val_loss: 0.1870 - val_accuracy: 0.9300 - lr: 0.0010\n",
            "Epoch 29/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.2184 - accuracy: 0.9162 - val_loss: 0.1838 - val_accuracy: 0.9312 - lr: 0.0010\n",
            "Epoch 30/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.2181 - accuracy: 0.9167 - val_loss: 0.1908 - val_accuracy: 0.9273 - lr: 0.0010\n",
            "Epoch 31/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.2157 - accuracy: 0.9178 - val_loss: 0.1828 - val_accuracy: 0.9321 - lr: 0.0010\n",
            "Epoch 32/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.2138 - accuracy: 0.9183 - val_loss: 0.1895 - val_accuracy: 0.9302 - lr: 0.0010\n",
            "Epoch 33/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.2130 - accuracy: 0.9186 - val_loss: 0.1848 - val_accuracy: 0.9313 - lr: 0.0010\n",
            "Epoch 34/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.2095 - accuracy: 0.9196 - val_loss: 0.1835 - val_accuracy: 0.9309 - lr: 0.0010\n",
            "Epoch 35/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.2096 - accuracy: 0.9195 - val_loss: 0.1789 - val_accuracy: 0.9331 - lr: 0.0010\n",
            "Epoch 36/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.2061 - accuracy: 0.9206 - val_loss: 0.1865 - val_accuracy: 0.9315 - lr: 0.0010\n",
            "Epoch 37/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.2061 - accuracy: 0.9219 - val_loss: 0.1817 - val_accuracy: 0.9311 - lr: 0.0010\n",
            "Epoch 38/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.2034 - accuracy: 0.9222 - val_loss: 0.1896 - val_accuracy: 0.9280 - lr: 0.0010\n",
            "Epoch 39/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.2046 - accuracy: 0.9211 - val_loss: 0.1870 - val_accuracy: 0.9283 - lr: 0.0010\n",
            "Epoch 40/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1851 - accuracy: 0.9284 - val_loss: 0.1661 - val_accuracy: 0.9384 - lr: 2.0000e-04\n",
            "Epoch 41/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1792 - accuracy: 0.9317 - val_loss: 0.1684 - val_accuracy: 0.9367 - lr: 2.0000e-04\n",
            "Epoch 42/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1766 - accuracy: 0.9320 - val_loss: 0.1672 - val_accuracy: 0.9381 - lr: 2.0000e-04\n",
            "Epoch 43/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1769 - accuracy: 0.9321 - val_loss: 0.1661 - val_accuracy: 0.9390 - lr: 2.0000e-04\n",
            "Epoch 44/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1751 - accuracy: 0.9319 - val_loss: 0.1630 - val_accuracy: 0.9394 - lr: 2.0000e-04\n",
            "Epoch 45/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1724 - accuracy: 0.9348 - val_loss: 0.1621 - val_accuracy: 0.9400 - lr: 2.0000e-04\n",
            "Epoch 46/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1701 - accuracy: 0.9343 - val_loss: 0.1613 - val_accuracy: 0.9404 - lr: 2.0000e-04\n",
            "Epoch 47/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1713 - accuracy: 0.9338 - val_loss: 0.1674 - val_accuracy: 0.9387 - lr: 2.0000e-04\n",
            "Epoch 48/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1686 - accuracy: 0.9356 - val_loss: 0.1601 - val_accuracy: 0.9417 - lr: 2.0000e-04\n",
            "Epoch 49/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1711 - accuracy: 0.9339 - val_loss: 0.1597 - val_accuracy: 0.9419 - lr: 2.0000e-04\n",
            "Epoch 50/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1661 - accuracy: 0.9357 - val_loss: 0.1604 - val_accuracy: 0.9422 - lr: 2.0000e-04\n",
            "Epoch 51/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1704 - accuracy: 0.9348 - val_loss: 0.1580 - val_accuracy: 0.9432 - lr: 2.0000e-04\n",
            "Epoch 52/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1681 - accuracy: 0.9352 - val_loss: 0.1597 - val_accuracy: 0.9423 - lr: 2.0000e-04\n",
            "Epoch 53/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1669 - accuracy: 0.9365 - val_loss: 0.1590 - val_accuracy: 0.9424 - lr: 2.0000e-04\n",
            "Epoch 54/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1659 - accuracy: 0.9355 - val_loss: 0.1579 - val_accuracy: 0.9441 - lr: 2.0000e-04\n",
            "Epoch 55/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1647 - accuracy: 0.9366 - val_loss: 0.1591 - val_accuracy: 0.9435 - lr: 2.0000e-04\n",
            "Epoch 56/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1599 - accuracy: 0.9377 - val_loss: 0.1557 - val_accuracy: 0.9439 - lr: 4.0000e-05\n",
            "Epoch 57/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1597 - accuracy: 0.9379 - val_loss: 0.1559 - val_accuracy: 0.9438 - lr: 4.0000e-05\n",
            "Epoch 58/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1588 - accuracy: 0.9383 - val_loss: 0.1549 - val_accuracy: 0.9445 - lr: 4.0000e-05\n",
            "Epoch 59/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1595 - accuracy: 0.9390 - val_loss: 0.1552 - val_accuracy: 0.9450 - lr: 4.0000e-05\n",
            "Epoch 60/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1589 - accuracy: 0.9377 - val_loss: 0.1550 - val_accuracy: 0.9447 - lr: 4.0000e-05\n",
            "Epoch 61/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1583 - accuracy: 0.9389 - val_loss: 0.1552 - val_accuracy: 0.9446 - lr: 4.0000e-05\n",
            "Epoch 62/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1582 - accuracy: 0.9388 - val_loss: 0.1554 - val_accuracy: 0.9438 - lr: 4.0000e-05\n",
            "Epoch 63/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1579 - accuracy: 0.9381 - val_loss: 0.1552 - val_accuracy: 0.9445 - lr: 8.0000e-06\n",
            "Epoch 64/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1557 - accuracy: 0.9401 - val_loss: 0.1548 - val_accuracy: 0.9445 - lr: 8.0000e-06\n",
            "Epoch 65/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1571 - accuracy: 0.9396 - val_loss: 0.1548 - val_accuracy: 0.9441 - lr: 8.0000e-06\n",
            "Epoch 66/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1582 - accuracy: 0.9396 - val_loss: 0.1546 - val_accuracy: 0.9440 - lr: 8.0000e-06\n",
            "Epoch 67/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1572 - accuracy: 0.9391 - val_loss: 0.1548 - val_accuracy: 0.9444 - lr: 8.0000e-06\n",
            "Epoch 68/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1553 - accuracy: 0.9392 - val_loss: 0.1546 - val_accuracy: 0.9444 - lr: 8.0000e-06\n",
            "Epoch 69/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1570 - accuracy: 0.9389 - val_loss: 0.1545 - val_accuracy: 0.9445 - lr: 8.0000e-06\n",
            "Epoch 70/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1576 - accuracy: 0.9391 - val_loss: 0.1546 - val_accuracy: 0.9446 - lr: 8.0000e-06\n",
            "Epoch 71/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1580 - accuracy: 0.9388 - val_loss: 0.1543 - val_accuracy: 0.9453 - lr: 8.0000e-06\n",
            "Epoch 72/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1578 - accuracy: 0.9381 - val_loss: 0.1542 - val_accuracy: 0.9449 - lr: 8.0000e-06\n",
            "Epoch 73/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1579 - accuracy: 0.9385 - val_loss: 0.1541 - val_accuracy: 0.9450 - lr: 8.0000e-06\n",
            "Epoch 74/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1558 - accuracy: 0.9391 - val_loss: 0.1541 - val_accuracy: 0.9451 - lr: 8.0000e-06\n",
            "Epoch 75/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1561 - accuracy: 0.9401 - val_loss: 0.1543 - val_accuracy: 0.9445 - lr: 8.0000e-06\n",
            "Epoch 76/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1574 - accuracy: 0.9397 - val_loss: 0.1541 - val_accuracy: 0.9450 - lr: 8.0000e-06\n",
            "Epoch 77/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1568 - accuracy: 0.9395 - val_loss: 0.1538 - val_accuracy: 0.9449 - lr: 8.0000e-06\n",
            "Epoch 78/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1556 - accuracy: 0.9384 - val_loss: 0.1541 - val_accuracy: 0.9448 - lr: 8.0000e-06\n",
            "Epoch 79/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1565 - accuracy: 0.9396 - val_loss: 0.1540 - val_accuracy: 0.9448 - lr: 8.0000e-06\n",
            "Epoch 80/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1565 - accuracy: 0.9399 - val_loss: 0.1538 - val_accuracy: 0.9457 - lr: 8.0000e-06\n",
            "Epoch 81/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1576 - accuracy: 0.9390 - val_loss: 0.1545 - val_accuracy: 0.9448 - lr: 8.0000e-06\n",
            "Epoch 82/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1560 - accuracy: 0.9396 - val_loss: 0.1541 - val_accuracy: 0.9454 - lr: 1.6000e-06\n",
            "Epoch 83/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1583 - accuracy: 0.9388 - val_loss: 0.1540 - val_accuracy: 0.9454 - lr: 1.6000e-06\n",
            "Epoch 84/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1580 - accuracy: 0.9397 - val_loss: 0.1540 - val_accuracy: 0.9454 - lr: 1.6000e-06\n",
            "Epoch 85/85\n",
            "844/844 [==============================] - 5s 6ms/step - loss: 0.1570 - accuracy: 0.9397 - val_loss: 0.1540 - val_accuracy: 0.9453 - lr: 1.6000e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dokładność modelu\n",
        "Na podstawie danych testowych pochodzących z pierwotnego (bez augmentacji) zbioru danych Fashion_Mnist"
      ],
      "metadata": {
        "id": "Py_CZlqA7rAq"
      },
      "id": "Py_CZlqA7rAq"
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = tf.keras.datasets.fashion_mnist.load_data()\n",
        "images, labels = test\n",
        "images = images/255.0\n",
        "labels = labels.astype(np.int32)\n",
        "score = f_mnist_model.evaluate(images, labels)\n",
        "score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSzCpSPT4BrN",
        "outputId": "bca48209-c670-467f-bdd8-38f1cf980e83"
      },
      "id": "NSzCpSPT4BrN",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2031 - accuracy: 0.9303\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.20314054191112518, 0.9302999973297119]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wnioski:\n",
        "\n",
        "Uważam, że nie jest źle. Model bywał przetrenowywany, więc w celu złagodzenia tej sytuacji zastosowałam w modelu Dropout().\n",
        "\n",
        "W internecie (przynajmniej tam, gdzie ja dotarłam) rzadko kto zwraca uwagę na accuracy na danych testowych. Wystarcza, że sam wytrenowany na danych treningowych model ma wysoką dokładność i nie zwraca się uwagi na przetrenowanie modelu. W tych okolicznościach osiągnięcie przez laika (czyli mnie) accuracy ~.93 na danych testowych uważam za sukces."
      ],
      "metadata": {
        "id": "7ftDdutC7yns"
      },
      "id": "7ftDdutC7yns"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "b7a57a4211723189e59ed97bb1ea409ea2cac14a050c5f93135514b2300d7318"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}